{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from IPython.lib.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 07 (Monday), AST 8581 / PHYS 8581 / CSCI 8581: Big Data in Astrophysics\n",
    "\n",
    "### Michael Coughlin <cough052@umn.edu>, Michael Steinbach <stei0062@umn.edu>, Nico Adams adams900@umn.edu\n",
    "\n",
    "\n",
    "with contributions totally ripped off from Gautham Narayan (UIUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where do we stand?\n",
    "\n",
    "Foundations of Data and Probability -> Statistical frameworks (Frequentist vs Bayesian) -> Estimating underlying distributions -> Analysis of Time series (periodicity) -> Analysis of Time series (variability) -> Analysis of Time series (stochastic processes) -> Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Last Class: Stochastic Processes and Correlation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today: so if you have a correlation function, how do you get to $y(t)$? Gaussian Processes!\n",
    "\n",
    "\n",
    "A stochastic process is collection of variables drawn from _a probability distribution over functions_.\n",
    "\n",
    "In other words, if our function of interest is $y(t)$, a stochastic process assigns probabilities $P\\left[y(t)\\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gaussian Processes\n",
    "\n",
    "A Gaussian process has the property that\n",
    "\n",
    "$P\\left[y(x) | y(x_1), y(x_2), \\ldots\\right]$\n",
    "\n",
    "is a Gaussian depending on the $x_i$ and $y(x_i)$. The process is specified by a \"mean function\" $\\mu(x)$ and a \"covariance function\" $C(x)$, or \"kernel,\" which determines how quickly $y(x)$ can vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes in Data Analysis\n",
    "\n",
    "A draw from $P[y(x^*)]$ would represent a prior prediction for the function value $y(x^*)$\n",
    "\n",
    "Typically we are more interested in the posterior prediction, drawn from $P[y(x^*)\\vert y^{\\rm obs}(x_{\\rm obs})]$\n",
    "\n",
    "$$ \\log L = - \\log | \\Sigma| - |y -u|^T \\Sigma^{-1} |y-u|$$\n",
    "\n",
    "\n",
    "$$ \\Sigma = (n x n)\\text{ matrix}$$ \n",
    "\n",
    "with \n",
    "\n",
    "$$ \\Sigma_{i,j} = \\text{Cov}(y(t_i), y(t_j)) = \\int_{-\\infty}^{\\infty} \\text{PSD} e^{2\\pi if |t_i - t_j|} \\,df $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The posterior PDF for $y(x^*)$ is a Gaussian, whose mean and standard deviation can be computed algebraically, and which is constrained by _all the previously observed $y(x)$_.\n",
    "\n",
    "\n",
    "<img src=\"figures/mfm_gp_example.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GP Regression\n",
    "\n",
    "GP's provide a natural way to achieve high flexibility (and uncertainty) when _interpolating_ data. \n",
    "\n",
    "With the appropriate assumptions (e.g. Gaussian measurement errors), the calculation of the posterior for $y(x)$ is an _algebraic_ operation (no Monte Carlo required).\n",
    "\n",
    "Marginalization over the GP hyperparameters (the width of the kernel, for example) is more computationally expensive (involving the determinants of the matrices), but [fast methods have been developed](http://dan.iel.fm/george/current/user/hyper/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian Processes are examples of Model \"free\" models - aka \"non-parametric models\"\n",
    "\n",
    "\n",
    "Sometimes we simply don't have a good first-principles model for what's going on in our data, but we're also confident that making a simple assumption (e.g. Gaussian scatter) is dead wrong.\n",
    "\n",
    "### What does \"model-free\" mean?\n",
    "\n",
    "In these situations, we're motivated to avoid strong modeling assumptions and instead be more empirical.\n",
    "\n",
    "Common adjectives:\n",
    "* non-parametric\n",
    "* model-independent\n",
    "* data-driven\n",
    "* empirical\n",
    "\n",
    "(Strictly speaking, these tend to correspond to models with very many parameters, but the terminology persists.)\n",
    "\n",
    "Gaussian processes appear to be \"non-parametric\" because the algebraic evaluation of the posterior PDF includes analytic marginalization over all the (nuisance) parameters in the model (the true values of $y$ at each $x_{\\rm obs}$).\n",
    "\n",
    "As with all non-parametric models, GPs are not \"assumption-free\" or \"model-independent\": they are just not _simply_ or _physically_ parametrized, and so involve different _types_ of assumptions.\n",
    "\n",
    "The trade-off between simply-parametrized and non-parametric models is between _interpretability_ (typically high for simply-parametrized physical models) and _prediction accuracy_ (typically high for non-parametric models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "During the first half of the semester, you got famililar with observations drawn from a distribution e.g. $y1$, drawn from a Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$:\n",
    "\n",
    "\\begin{align}\n",
    "p(y_1 | \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left[ - \\frac{(y_1-\\mu)^2}{2 \\sigma^2} \\right] \n",
    "\\end{align}\n",
    "\n",
    "i.e.\n",
    "\n",
    "### $$y_1 \\sim \\mathcal{N}(\\mu,\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If pair of variables $y_1$ and $y_2$, drawn from a *bivariate Gaussian distribution*. The *joint probability density* for $y_1$ and $y_2$ is:\n",
    "\n",
    "### $$\n",
    "\\left[ \\begin{array}{l} y_1 \\\\ y_2 \\end{array} \\right] \\sim \\mathcal{N} \\left(\n",
    "\\left[ \\begin{array}{l} \\mu_1 \\\\ \\mu_2 \\end{array}  \\right] , \n",
    "\\left[ \\begin{array}{ll} \n",
    "\\sigma_1^2 & C \\\\\n",
    "C & \\sigma_2^2 \n",
    "\\end{array}  \\right] \n",
    "\\right),\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "### $$C = {\\rm cov}(y_1,y_2)$$ \n",
    "\n",
    "is the *covariance* between $y_1$ and $y_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the first half of the semester, we dealt with independent variables i.e.\n",
    "\n",
    "### $$P(y_1 \\cap y_2) = P(y_1) \\cdot P(y_2) $$\n",
    "\n",
    "and consequently\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "P(y_2|y_1) = \\frac{P(y_1 \\cap y_2)}{P(y_1)} = P(y_2)\n",
    "\\end{align}\n",
    "\n",
    "If two variables are independent, then $C = 0$ (remember converse isn't true). \n",
    "\n",
    "The observations are *uncorrelated* so measuring $y_1$ doesn't teach us anything about $y_2$.\n",
    "\n",
    "(If in addition $\\mu_1 = \\mu_2$ and $\\sigma_1 = \\sigma_2$ the variables are i.i.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### With time-series, $C \\ne 0$ \n",
    "\n",
    "If we know the value of $y_1$, the probability density for $y_2$ collapses to the the *conditional distribution* of $y_2$ given $y_1$:\n",
    "\n",
    "### $$\n",
    "p(y_2 \\mid y_1) = \\mathcal{N} \\left( \\mu_2 + C (y_1-\\mu_1)/\\sigma_1^2, \\sigma_2^2-C^2\\sigma_1^2 \\right).\n",
    "$$\n",
    "\n",
    "### Now consider $N$ variables drawn from a multivariate Gaussian distribution:\n",
    "\n",
    "### $$\n",
    "\\boldsymbol{y} \\sim \\mathcal{N} (\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "### $$\\boldsymbol{y} = (y_1,y_2,\\ldots,y_N)^T$$\n",
    "\n",
    "### $$\\boldsymbol{\\mu} = (\\mu_1,\\mu_2,\\ldots,\\mu_N)^T$$ \n",
    "\n",
    "\n",
    "is the *mean vector*, and $\\boldsymbol{\\Sigma}$ is an $N \\times N$ positive semi-definite *covariance matrix*, with elements \n",
    "\n",
    "### $$\\Sigma_{ij}={\\rm cov}(y_i,y_j)$$\n",
    "\n",
    "### And then the likelihood generalizes from 1D:\n",
    "\n",
    "\\begin{align}\n",
    "p(y_1 | \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left[ - \\frac{(y_1-\\mu)^2}{2 \\sigma^2} \\right] \n",
    "\\end{align}\n",
    "\n",
    "### to ND:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "p(\\boldsymbol{y} | \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\frac{1}{\\sqrt{2 \\pi^N |\\Sigma|} } \\exp \\left[ -\\frac{1}{2} (\\boldsymbol{y} - \\boldsymbol{\\mu})^T \\Sigma^{-1} (\\boldsymbol{y} - \\boldsymbol{\\mu}) \\right] \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This works because:\n",
    "\n",
    "<img src=\"figures/gaussians_all_the_way_down.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Gaussian process is an extension of this concept to infinite $N$.\n",
    "\n",
    "This gives rise to a probability distribution over functions, rather than finite $N$ samples. \n",
    "\n",
    "<img src=\"figures/gp.png\">\n",
    "\n",
    "Informally - infinitely long vector ~ function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Again, for finite number of $y$ drawn from a multivariate normal distribution:\n",
    "\n",
    "### $$\n",
    "\\boldsymbol{y} \\sim \\mathcal{N} (\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\n",
    "$$\n",
    "\n",
    "This clearly doesn't make sense for infinite $N$, but the essential feature remains the same:\n",
    "### A Gaussian process is completely specified by its *mean function* and *covariance function*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Incorporating observational error is similar to what you did in the past as well:\n",
    "\n",
    "### $$ y \\sim f(t) + \\epsilon$$ \n",
    "\n",
    "### with deviations from the truth related to the observational uncertainties\n",
    "\n",
    "### $$ \\epsilon \\sim \\mathcal{N}(0, \\sigma_y^2) $$\n",
    "\n",
    "\n",
    "### except now, $f(t)$ is a function not of some parameters, but rather of functions thenselves:\n",
    "\n",
    "###  $$ f(t) \\sim \\mathcal{GP}(m(t), k(t,t'))$$\n",
    "\n",
    "### where I'm switching from $\\mu$ to $m(t)$ and $\\Sigma$ to $k(t, t')$ just to make explicit that these are not vectors.\n",
    "\n",
    "I'm using $k$ because this function that describes the covariance between time $t$ and $t'$ is called a **kernel** function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Thankfully, in the real world, we only have a finite number of observations\n",
    "\n",
    "Previously, we saw:\n",
    "\n",
    "### $$\\Sigma_{ij}={\\rm cov}(y_i,y_j)$$\n",
    "\n",
    "We don't have a parameteric model for $y$ anymore, but that's OK, we can write down a parametric model for the covariance itself, i.e.:\n",
    "\n",
    "### $$\n",
    "\\mathrm{cov}(y(t),y(t'))=k(t,t') $$\n",
    "\n",
    "\n",
    "That's helpful to do, because with finite observations:\n",
    "\n",
    "### $$\n",
    "\\mathrm{cov}(y_i,y_j)=k(t_i,t_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So we don't have parametrized model, but do have parametrized covariance - what can we do with this thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The prior\n",
    "\n",
    "Now consider a finite set of observations: inputs $\\boldsymbol{t}$, with corresponding outputs $\\boldsymbol{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The *joint distribution* of $\\boldsymbol{y}$ given $\\boldsymbol{t}$, $m$ and $k$ is\n",
    "\n",
    "### $$\n",
    "\\mathrm{p}(\\boldsymbol{y} \\mid \\boldsymbol{t},m,k) = \\mathcal{N}( \\boldsymbol{m},K),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "where again, $\\boldsymbol{m}=m(\\boldsymbol{t})$ is the *mean vector* \n",
    "\n",
    "and $K$ is the *covariance matrix*, with elements $K_{ij} = k(t_i,t_j)$.\n",
    "\n",
    "Note, there isn't one single function, but infinitely many for a specific choice of $m$, $k$. We marginalize over them to find the posterior mean. The parameters of $m$ and $k$ are called \"hyper parameters\". The interesting bit here is the covariance function/kernel, $k$ (we can always recenter the data to have mean = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test and training sets\n",
    "\n",
    "Suppose we have an (observed) *training set* $(\\boldsymbol{t},\\boldsymbol{y})$. \n",
    "\n",
    "We are interested in some other *test set* of inputs $\\boldsymbol{t}_*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The joint distribution over the training and test sets is\n",
    "### $$\n",
    "\\mathrm{p} \\left( \\left[ \\begin{array}{l} \\boldsymbol{y} \\\\ \\boldsymbol{y}_* \\end{array} \\right] \\right) \n",
    "= \\mathcal{N} \\left( \\left[ \\begin{array}{l} \\boldsymbol{m} \\\\ \\boldsymbol{m}_* \\end{array} \\right], \n",
    "\\left[ \\begin{array}{ll} K & K_* \\\\ K_*^T & K_{**} \\end{array} \\right] \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "where $\\boldsymbol{m}_* = m(\\boldsymbol{x}_*)$, $K_{**,ij} = k(t_{*,i},t_{*,j})$ and $K_{*,ij} = k(t_i,t_{*,j})$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is not really any different from when we just had two observations:\n",
    "\n",
    "### $$\n",
    "\\left[ \\begin{array}{l} y_1 \\\\ y_2 \\end{array} \\right] \\sim \\mathcal{N} \\left(\n",
    "\\left[ \\begin{array}{l} \\mu_1 \\\\ \\mu_2 \\end{array}  \\right] , \n",
    "\\left[ \\begin{array}{ll} \n",
    "\\sigma_1^2 & C \\\\\n",
    "C & \\sigma_2^2 \n",
    "\\end{array}  \\right] \n",
    "\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# For notational brevity I'm going to set the mean to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The conditional distribution\n",
    "\n",
    "The *conditional distribution* for the test set given the training set is:\n",
    "\n",
    "### $$ \n",
    "\\mathrm{p} ( \\boldsymbol{y}_* \\mid \\boldsymbol{y},k) = \\mathcal{N} ( \n",
    "K_*^T K^{-1} \\boldsymbol{y}, K_{**} - K_*^T K^{-1} K_* ).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is also just a straight forward generalization from what we had with just two points:\n",
    "\n",
    "### $$\n",
    "p(y_2 \\mid y_1) = \\mathcal{N} \\left( \\mu_2 + C (y_1-\\mu_1)/\\sigma_1^2, \\sigma_2^2-C^2\\sigma_1^2 \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is called the **predictive distribution**, because it can be use to predict future (or past) observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "More generally, it can be used for *interpolating* the observations to any desired set of inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is one of the most widespread applications of GPs in some fields (e.g. kriging in geology, economic forecasting, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Real observations always contain a component of *white noise*\n",
    "\n",
    "We need to account for this, but don't necessarily want to include in the predictions. \n",
    "\n",
    "\n",
    "If the white noise variance $\\sigma^2$ is constant, we can write \n",
    "\n",
    "### $$\n",
    "\\mathrm{cov}(y_i,y_j)=k(t_i,t_j)+\\delta_{ij} \\sigma^2,\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and the conditional distribution becomes\n",
    "\n",
    "\n",
    "### $$ \n",
    "\\mathrm{p} ( \\boldsymbol{y}_* \\mid \\boldsymbol{y},k) = \\mathcal{N} ( \n",
    "K_*^T (K + \\sigma^2 \\mathbb{I})^{-1} \\boldsymbol{y}, K_{**} - K_*^T (K + \\sigma^2 \\mathbb{I})^{-1} K_* ).\n",
    "$$\n",
    "\n",
    "\n",
    "We assumed constant white noise, but it's trivial to allow for different $\\sigma$ for each data point.\n",
    "\n",
    "You could also add some intrinsic dispersion as you often have to do. \n",
    "\n",
    "In real life, we may need to learn $\\sigma_{\\text{int}}$ from the data, alongside the other contribution to the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Single-point prediction\n",
    "\n",
    "Let us look more closely at the predictive distribution for a single test point $t_*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is a Gaussian with mean:\n",
    "### $$\n",
    "\\overline{y}_* = \\boldsymbol{k}_*^T (K + \\sigma^2 \\mathbb{I})^{-1} \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "and variance\n",
    "### $$\n",
    "\\mathbb{V}[y_*] = k(t_*,t_*) - \\boldsymbol{k}_*^T (K + \\sigma^2 \\mathbb{I})^{-1} \\boldsymbol{k}_*,\n",
    "$$\n",
    "where $\\boldsymbol{k}_*$ is the vector of covariances between the test point and the training points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice the mean is a linear combination of the observations: the GP is a *linear predictor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is also a linear combination of covariance functions, each centred on a training point:\n",
    "\n",
    "### $$\n",
    "\\overline{y}_* = \\sum_{i=1}^N \\alpha_i k(x_i,x_*),\n",
    "$$\n",
    "where $\\alpha_i = (K + \\sigma^2 \\mathbb{I})^{-1} y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The likelihood\n",
    "\n",
    "The *likelihood* of the data under the GP model is simply:\n",
    "\n",
    "### $$\n",
    "\\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{t}) = \\mathcal{N}(\\boldsymbol{y} \\, | \\, \\boldsymbol{0},K + \\sigma^2 \\mathbb{I}).\n",
    "$$\n",
    "\n",
    "This is a measure of how well the model explains, or predicts, the training set.\n",
    "\n",
    "i.e. **The observed $\\boldsymbol{y}$ are noisy realisations of a latent (unobserved) Gaussian process $\\boldsymbol{f}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are marginalizing over the function values $\\boldsymbol{f}$:\n",
    "### $$\n",
    "\\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{t}) = \\int \\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{f},\\boldsymbol{t}) \\, \\mathrm{p}(\\boldsymbol{f} \\,|\\, \\boldsymbol{t}) \\, \\mathrm{d}\\boldsymbol{f},\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "\n",
    "### $$\n",
    "\\mathrm{p}(\\boldsymbol{f} \\,|\\, \\boldsymbol{t}) = \\mathcal{N}(\\boldsymbol{f} \\, | \\, \\boldsymbol{0},K)\n",
    "$$\n",
    "\n",
    "\n",
    "is the *prior*, and \n",
    "\n",
    "\n",
    "### $$\n",
    "\\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{f},\\boldsymbol{t}) = \\mathcal{N}(\\boldsymbol{y} \\, | \\, \\boldsymbol{0},\\sigma^2 \\mathbb{I})\n",
    "$$\n",
    "is the *likelihood*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# You \"condition\" the hyperparameters on some observed data\n",
    "\n",
    "i.e. evaluate the conditional (or predictive) distribution for a given covariance matrix (i.e. covariance function and hyper-parameters), and training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## *Training* the GP...\n",
    "\n",
    "...means maximising the *likelihood* of the model with respect to the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## The kernel trick\n",
    "\n",
    "Consider a linear basis model with arbitrarily many *basis functions*, or *features*, $\\Phi(x)$, and a (Gaussian) prior $\\Sigma_{\\mathrm{p}}$ over the basis function weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You end up with exactly the same expressions for the predictive distribution and the likelihood so long as:\n",
    "### $$\n",
    "k(\\boldsymbol{x},\\boldsymbol{x'}) = \\Phi(\\boldsymbol{x})^{\\mathrm{T}} \\Sigma_{\\mathrm{p}} \\Phi(\\boldsymbol{x'}),\n",
    "$$\n",
    "\n",
    "\n",
    "or, writing $\\Psi(\\boldsymbol{x}) = \\Sigma_{\\mathrm{p}}^{1/2} \\Phi(\\boldsymbol{x})$,\n",
    "\n",
    "\n",
    "### $$\n",
    "k(\\boldsymbol{x},\\boldsymbol{x'}) = \\Psi(\\boldsymbol{x}) \\cdot \\Psi(\\boldsymbol{x'}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Thus the covariance function $k$ enables us to go from a (finite) *input space* to a (potentially infinite) *feature space*. This is known as the *kernel trick* and the covariance function is often referred to as the *kernel*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class warm-up: a worked Gaussian Process example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by considering a simple function: $f(x) = x * \\sin(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "np.random.seed(2)\n",
    "def f(x):\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    return x * np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmax = 10\n",
    "X_space = np.linspace(0.001, xmax - 0.001, 1000)\n",
    "\n",
    "# Get the \"real\" value\n",
    "y_real = f(X_space)\n",
    "\n",
    "n = 10\n",
    "# Uniform sampling and add Gaussian noise\n",
    "x_sample = np.random.random(n)*10\n",
    "\n",
    "sigma = 1.0\n",
    "noise = np.random.normal(0, sigma, n)\n",
    "y_meas = f(x_sample) + noise\n",
    "\n",
    "plt.plot(X_space,y_real,\"r\")\n",
    "plt.errorbar(x_sample,y_meas,yerr=sigma,fmt=\"bo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world we just have the data and we want to predict a new value (in this case, at $x_p$ = 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma = 1.0\n",
    "y_p = 0.0\n",
    "x_p = 5.0\n",
    "plt.plot(x_sample,y_meas,\"bo\",label=\"$\\mathbf{y}$\")\n",
    "plt.errorbar(x_p,y_p,yerr=sigma,fmt=\"ro\",label=\"$\\hat{y}$\",alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlim(0,10)\n",
    "ylim=plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_comb = np.append(x_p,x_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From last class, we model the random vector (a priori) as $$\\begin{bmatrix}\\hat{Y} \\\\ \\mathbf{Y} \\end{bmatrix} \\sim Pr\\left(\\begin{bmatrix}\\hat{Y} \\\\ \\mathbf{Y} \\end{bmatrix} = \\begin{bmatrix}\\hat{y} \\\\ \\mathbf{y} \\end{bmatrix}\\right) = \\mathcal{N}\\left(\\begin{bmatrix}0 \\\\ \\mathbf{0} \\end{bmatrix}, \\begin{bmatrix} K(\\hat{x},\\hat{x}) & K(\\hat{x},\\mathbf{x}) \\\\ K(\\mathbf{x},\\hat{x}) & K(\\mathbf{x},\\mathbf{x}) \\end{bmatrix}\\right) = \\mathcal{N}\\left(\\begin{bmatrix}0 \\\\ \\mathbf{0} \\end{bmatrix}, \\begin{bmatrix} a & \\mathbf{b}^T \\\\  \\mathbf{b} & C \\end{bmatrix}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.570975251039949, 2.7362768371568604)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(x_sample,np.zeros((n,1)),fmt=\"bo\",label=\"$\\mathbf{y}$\",yerr=sigma)\n",
    "plt.errorbar(x_p,0,yerr=sigma,fmt=\"ro\",label=\"$\\hat{y}$\")\n",
    "plt.legend()\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do is to do is to **update** this model with our data:\n",
    "\n",
    "$$\\hat{y} \\sim Pr(\\hat{Y}=\\hat{y}| \\mathbf{Y} = \\mathbf{y}) = \\mathcal{N}\\left(\\hat{y};\\mathbf{b}^T C^{-1} \\mathbf{y},  a - \\mathbf{b}^T C^{-1} \\mathbf{b} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = S[0,0]\n",
    "b = S[0,1:]\n",
    "C = S[1:,1:]\n",
    "Cinv = np.linalg.inv(C)\n",
    "mu_p = # b^T C^{-1} y\n",
    "sig_p = # a - b^T C^{-1} b\n",
    "plt.plot(x_sample,y_meas,\"bo\",label=\"$\\mathbf{y}$\")\n",
    "plt.errorbar(x_p,mu_p,yerr=sig_p,fmt=\"ro\",label=\"$\\hat{y}$\")\n",
    "plt.legend()\n",
    "plt.xlim(0,10)\n",
    "ylim=plt.ylim()\n",
    "plt.plot(X_space,y_real,\"r--\",alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS LOOKS AWFUL! But why? Make a plot of $C^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Try adding a small number (0.01) to the diagonal C and recompute $C^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lamb = 0.01\n",
    "Cinv = #np.linalg.inv(...\n",
    "mu_p = # b^T C^{-1} y\n",
    "sig_p = # a - b^T C^{-1} b\n",
    "plt.plot(x_sample,y_meas,\"bo\",label=\"$\\mathbf{y}$\")\n",
    "plt.errorbar(x_p,mu_p,yerr=sig_p,fmt=\"ro\",label=\"$\\hat{y}$\")\n",
    "plt.legend()\n",
    "plt.xlim(0,10)\n",
    "ylim=plt.ylim()\n",
    "plt.plot(X_space,y_real,\"r--\",alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS LOOKS BETTER But why? Make a plot of $C^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider that we want to do the same but for a vector of $\\mathbf{\\hat{y}}$ values for the $\\mathbf{\\hat{x}}$ points.\n",
    "\n",
    "$$\\begin{bmatrix}\\mathbf{\\hat{Y}} \\\\ \\mathbf{Y} \\end{bmatrix} \\sim Pr\\left(\\begin{bmatrix}\\mathbf{\\hat{Y}} \\\\ \\mathbf{Y} \\end{bmatrix} = \\begin{bmatrix}\\mathbf{\\hat{y}} \\\\ \\mathbf{y} \\end{bmatrix}\\right) = \\mathcal{N}\\left(\\begin{bmatrix}\\mathbf{0} \\\\ \\mathbf{0} \\end{bmatrix}, \\begin{bmatrix} K(\\mathbf{\\hat{x}},\\mathbf{\\hat{x}}) & K(\\mathbf{\\hat{x}},\\mathbf{x}) \\\\ K(\\mathbf{x},\\mathbf{\\hat{x}}) & K(\\mathbf{x},\\mathbf{x}) + \\lambda I \\end{bmatrix}\\right) = \\mathcal{N}\\left(\\begin{bmatrix}\\mathbf{0} \\\\ \\mathbf{0} \\end{bmatrix}, \\begin{bmatrix} A & B^T \\\\  B & C \\end{bmatrix}\\right) $$\n",
    "\n",
    "Now\n",
    "$$\\mathbf{\\hat{y}} \\sim Pr(\\mathbf{\\hat{Y}}=\\mathbf{\\hat{y}}| \\mathbf{Y} = \\mathbf{y}) = \\mathcal{N}\\left(\\mathbf{\\hat{y}} ; B^T C^{-1} \\mathbf{y},  A - B^T C^{-1} B \\right)$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to adopt a Kernel function (we will go through more of these next week...). We will use an Exponential Quadratic Kernel here:\n",
    "$$ \\Sigma_{ij} = K(x_j,x_i) = \\sigma^2 \\exp\\left(-\\frac{(x_j - x_i)^2}{2\\mathcal{l}^2} \\right)$$\n",
    "\n",
    "What does this metric look like in space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f9c197dea90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = 1.0\n",
    "X = np.atleast_2d(x_comb).T\n",
    "M=sklearn.metrics.pairwise_distances(X,X)\n",
    "S=sigma*sigma*np.exp(M*M/(-2*l*l))\n",
    "plt.imshow(S)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.atleast_2d(x_sample).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "X_space = np.linspace(0.1, 9.9, 1000)\n",
    "X_space = np.atleast_2d(X_space).T\n",
    "\n",
    "def gen_data(n = 10,sigma =1.0):\n",
    "    # Get the \"real\" value\n",
    "    x_sample = np.random.random(n)*10\n",
    "    noise = np.random.normal(0, sigma, n)\n",
    "    y_meas = f(x_sample) + noise\n",
    "    X = np.atleast_2d(x_sample).T\n",
    "    return(X,y_meas)\n",
    "\n",
    "def predict_GMM_plot(lamb=0.1,sigma=1.0,l=1.0,bars=False,instances=False):\n",
    "    dA=sklearn.metrics.pairwise_distances(X_space,X_space)\n",
    "    dB=sklearn.metrics.pairwise_distances(X,X_space)\n",
    "    dC=sklearn.metrics.pairwise_distances(X,X)\n",
    "    A=sigma*sigma*np.exp(dA*dA/(-2*l*l))\n",
    "    B=sigma*sigma*np.exp(dB*dB/(-2*l*l))\n",
    "    C=sigma*sigma*np.exp(dC*dC/(-2*l*l))\n",
    "    sI = lamb*np.eye(C.shape[0],C.shape[1])\n",
    "    Cinv = np.linalg.inv(C + sI)\n",
    "    mu_p = B.T.dot(Cinv).dot(y_meas)\n",
    "    cov_p = A - B.T.dot(Cinv).dot(B)\n",
    "    plt.plot(X,y_meas,\"bo\",label=\"$\\mathbf{y}$\")\n",
    "    if bars:\n",
    "        plt.errorbar(X_space,mu_p,yerr=1.96*np.diag(cov_p),fmt=\"r\",label=\"$\\mathbf{\\hat{y}}$\",alpha=0.2)\n",
    "    else:\n",
    "        plt.plot(X_space,mu_p,\"r\",label=\"$\\mathbf{\\hat{y}}$\",alpha=0.8)\n",
    "    plt.plot(X_space,y_real,\"k--\",alpha=0.5,label=\"f(x)\")\n",
    "    if instances:\n",
    "        #L=np.linalg.cholesky(cov_p)\n",
    "        for i in range(10):\n",
    "            inst=np.random.multivariate_normal(mu_p, cov_p)\n",
    "            #z = np.random.normal(0, 1.0, mu_p.length)\n",
    "            #inst = mu_p + L.dot(z)\n",
    "            plt.plot(X_space,inst,alpha=0.5)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlim(0,max(X_space))\n",
    "    ylim=plt.ylim() \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622e15e4462045a98e80c22ad670762f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lamb', max=1.0, step=0.01), FloatSlider(value=1.0, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_GMM_plot>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(predict_GMM_plot,lamb=(0.0,1.0,0.01),sigma=(0.1,2.0,0.1),l=(0.1,5.0,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1ff89f30af427a85013f51aad04e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lamb', max=1.0, step=0.01), FloatSlider(value=1.0, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_GMM_plot>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y_meas = gen_data(n=25,sigma=1.0)\n",
    "interact(predict_GMM_plot,lamb=(0.0,1.0,0.01),sigma=(0.1,4.0,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f643b06d44b4e03aac94b80d71c2dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lamb', max=1.0, step=0.01), FloatSlider(value=1.0, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_GMM_plot>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_space = np.linspace(0.1, 30.0, 1000)\n",
    "X_space = np.atleast_2d(X_space).T\n",
    "y_real = f(X_space)\n",
    "X,y_meas = gen_data(n=25,sigma=1.0)\n",
    "interact(predict_GMM_plot,lamb=(0.0,1.0,0.01),sigma=(1,40.0,1),l=(0.1,4.0,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class warm-up: We will try another one (a Periodic Kernel) here:\n",
    "\n",
    "$K(x,x') = \\sigma^2 exp\\left(−\\frac{2 sin^2\\left(\\frac{\\pi(x− x′)}{p}\\right)}{l^2}\\right)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_GMMper_plot(lamb=0.1,sigma=1.0,l=1.0,p=10.0,bars=False,instances=False):\n",
    "    dA=sklearn.metrics.pairwise_distances(X_space,X_space)\n",
    "    dB=sklearn.metrics.pairwise_distances(X,X_space)\n",
    "    dC=sklearn.metrics.pairwise_distances(X,X)\n",
    "    sA=# YOUR CODE HERE\n",
    "    sB=# YOUR CODE HERE\n",
    "    sC=# YOUR CODE HERE\n",
    "    A=# YOUR CODE HERE\n",
    "    B=# YOUR CODE HERE\n",
    "    C=# YOUR CODE HERE\n",
    "    sI = lamb*np.eye(C.shape[0],C.shape[1])\n",
    "    Cinv = np.linalg.inv(C + sI)\n",
    "    mu_p = B.T.dot(Cinv).dot(y_meas)\n",
    "    cov_p = A - B.T.dot(Cinv).dot(B)\n",
    "    plt.plot(X,y_meas,\"bo\",label=\"$\\mathbf{y}$\")\n",
    "    if bars:\n",
    "        plt.errorbar(X_space,mu_p,yerr=1.96*np.diag(cov_p),fmt=\"r\",label=\"$\\mathbf{\\hat{y}}$\",alpha=0.2)\n",
    "    else:\n",
    "        plt.plot(X_space,mu_p,\"r\",label=\"$\\mathbf{\\hat{y}}$\",alpha=0.8)\n",
    "    plt.plot(X_space,y_real,\"k--\",alpha=0.5,label=\"f(x)\")\n",
    "    if instances:\n",
    "        #L=np.linalg.cholesky(cov_p)\n",
    "        for i in range(10):\n",
    "            inst=np.random.multivariate_normal(mu_p, cov_p)\n",
    "            #z = np.random.normal(0, 1.0, mu_p.length)\n",
    "            #inst = mu_p + L.dot(z)\n",
    "            plt.plot(X_space,inst,alpha=0.5)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlim(0,max(X_space))\n",
    "    ylim=plt.ylim() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c1291dedd246b4b04d2081db161910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lamb', max=1.0, step=0.01), FloatSlider(value=1.0, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_GMMper_plot>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(predict_GMMper_plot,lamb=(0.0,1.0,0.01),sigma=(1,40.0,1),l=(0.1,4.0,0.1),p=(0.1,30.0,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class warm-up: We will try another one (a Periodic + Exponential Quadratic Kernel) here:\n",
    "\n",
    "$K(x,x') = \\sigma^2 exp\\left(−\\frac{2 sin^2\\left(\\frac{\\pi(x− x′)}{p}\\right)}{l^2}\\right) \\sigma^2 exp\\left(-\\frac{(x_j - x_i)^2}{2\\mathcal{l}^2} \\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_GMMcomb_plot(lamb=0.1,sigma=1.0,l=1.0,p=10.0,bars=False,instances=False):\n",
    "    dA=sklearn.metrics.pairwise_distances(X_space,X_space)\n",
    "    dB=sklearn.metrics.pairwise_distances(X,X_space)\n",
    "    dC=sklearn.metrics.pairwise_distances(X,X)\n",
    "    sA=# YOUR CODE HERE\n",
    "    sB=# YOUR CODE HERE\n",
    "    sC=# YOUR CODE HERE\n",
    "    A=# YOUR CODE HERE\n",
    "    B=# YOUR CODE HERE\n",
    "    C=# YOUR CODE HERE\n",
    "    sI = lamb*np.eye(C.shape[0],C.shape[1])\n",
    "    Cinv = np.linalg.inv(C + sI)\n",
    "    mu_p = B.T.dot(Cinv).dot(y_meas)\n",
    "    cov_p = A - B.T.dot(Cinv).dot(B)\n",
    "    plt.plot(X,y_meas,\"bo\",label=\"$\\mathbf{y}$\")\n",
    "    if bars:\n",
    "        plt.errorbar(X_space,mu_p,yerr=1.96*np.diag(cov_p),fmt=\"r\",label=\"$\\mathbf{\\hat{y}}$\",alpha=0.2)\n",
    "    else:\n",
    "        plt.plot(X_space,mu_p,\"r\",label=\"$\\mathbf{\\hat{y}}$\",alpha=0.8)\n",
    "    plt.plot(X_space,y_real,\"k--\",alpha=0.5,label=\"f(x)\")\n",
    "    if instances:\n",
    "        #L=np.linalg.cholesky(cov_p)\n",
    "        for i in range(10):\n",
    "            inst=np.random.multivariate_normal(mu_p, cov_p)\n",
    "            #z = np.random.normal(0, 1.0, mu_p.length)\n",
    "            #inst = mu_p + L.dot(z)\n",
    "            plt.plot(X_space,inst,alpha=0.5)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlim(0,max(X_space))\n",
    "    ylim=plt.ylim() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63260c8c784246cca9a035158a41a4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lamb', max=1.0, step=0.01), FloatSlider(value=1.0, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_GMMcomb_plot>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(predict_GMMcomb_plot,lamb=(0.0,1.0,0.01),sigma=(1,40.0,1),l=(0.1,4.0,0.1),p=(0.1,30.0,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kernel works best for the data we have? Any hypotheses as to why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix: Probabilistic Graphical Model for a GP\n",
    "\n",
    "\n",
    "### Recall:\n",
    "\n",
    "A **probabilistic graphical model** (PGM) is a very useful way of visualizing a generative model.\n",
    "* They sketch out the procedure for how one would generate mock data in practice.\n",
    "* They illustrate the interdependence of model parameters, and the dependence of data on parameters.\n",
    "* _They also (therefore) represent a conditional factorization of the PDF for all the data and model parameters._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ingredients of a PGM:\n",
    "* **Nodes** represent PDFs for parameters\n",
    "* **Edges** represent conditional relationships\n",
    "* **Plates** represent repeated model components whose contents are **conditionally independent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Types of nodes:\n",
    "* **Circles** represent a PDF. This parameter is a *stochastic* function of the parameters feeding into it.\n",
    "* **Points** represent a delta-function PDF. This parameter is a *deterministic* function of the parameters feeding into it.\n",
    "* **Double circles** (or shading) indicate measured data. They are stochastic in the context of generating mock data, but fixed in the context of parameter inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# If we were dealing with i.i.d. data\n",
    "\n",
    "### $$ y \\sim f(t) + \\epsilon$$ \n",
    "\n",
    "### with deviations from the truth related to the observational uncertainties\n",
    "\n",
    "### $$ \\epsilon \\sim \\mathcal{N}(0, \\sigma_y^2) $$\n",
    "\n",
    "\n",
    "<img src=\"figures/pgm_conditionally_independent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# With time-series the data are not conditionally independent\n",
    "\n",
    "i.e. you don't have a nice plate:\n",
    "\n",
    "<img src=\"figures/gp_pgm.png\">\n",
    "\n",
    "From [Rasmussen & Williams (aka the GP bible)](http://www.gaussianprocess.org/gpml/chapters/RW.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Random Process and Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/random_process.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/weight_space.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/two_views.jpg\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
